paths:
  gold_path: specs/gold_master_v4_text_plus_ids.json
  output_path: outputs/eval/ui_dashboard_data.json

runs:
  #P0_Baseline_full: outputs/P0/run_20260225_171720_papers10_p01-10_q1-49_nq490.jsonl
  #P1_Semantic_full: outputs/P1/run_20260225_174345_papers10_p01-10_q1-49_nq490.jsonl
  #p2_imp_hybrid_8: outputs/P2_imp/run_20260225_204755_papers1_p08-08_q1-49_nq49.jsonl
  #p3: outputs/P3/run_20260225_195541_papers1_p08-08_q1-49_nq49.jsonl
  #p3_new: outputs/P3/run_20260225_202948_papers1_p08-08_q1-49_nq49.jsonl
  #p3_top5: outputs/P3/run_20260225_211044_papers1_p08-08_q1-49_nq49.jsonl
  p3_top5-art1: outputs/P3/run_20260225_213156_papers1_p01-01_q1-7_nq7.jsonl

evaluation:
  default_k: 5
  numeric_tolerance: 0.05
  hallucination_threshold: 0.5
  no_gold_policy:
    enabled: true
    empty_answer_markers:
      - ""
      - none
      - null
      - n/a
      - na
      - unknown
      - not available
      - not reported
      - unmeasured
      - not measured
    status_markers:
      - unmeasured
      - not reported
      - missing
      - unknown
      - n/a
      - na
    abstention_markers:
      - cannot determine
      - can't determine
      - cannot be determined
      - insufficient context
      - insufficient information
      - not provided
      - not reported
      - unknown
      - not available
      - n/a
      - not mentioned
      - does not mention
      - does not include
      - does not specify
      - not specified
      - not in the context
      - not enough information
    abstention_qa_score: 1.0
    non_abstention_qa_score: 0.0
    non_abstention_groundedness_cap: 0.2
    force_hallucination_on_non_abstention: true
    exclude_retrieval_from_aggregate: true
  gold_present_policy:
    enabled: true
    abstention_qa_cap: 0.0
    abstention_semantic_cap: 0.0
    abstention_groundedness_cap: 0.2
    force_hallucination_on_abstention: true
    enforce_numeric_coverage_for_free_text: true
    min_gold_numeric_facts: 2
  qa_lambda:
    NUMERIC: 0.2
    LIST: 0.2
    STRING: 0.0
    CATEGORICAL: 0.0
    FREE_TEXT: 0.0
  final_weights:
    w_qa: 0.6
    w_gr: 0.2
    w_ret: 0.1
    w_eff: 0.1

pricing:
  embedding:
    text-embedding-3-small: 0.02
    text-embedding-3-large: 0.13
  llm:
    gpt-4o-mini:
      input_per_million: 0.15
      output_per_million: 0.6
    gpt-4o:
      input_per_million: 2.5
      output_per_million: 10.0

judge:
  enabled: true
  model: gpt-4o-mini
  temperature: 0.0
  max_tokens: 500

logging:
  level: INFO
  progress_every_questions: 10
  log_question_details: false
